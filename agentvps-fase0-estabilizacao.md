# üîß AgentVPS ‚Äî FASE 0: Estabiliza√ß√£o v1

## Por que esta fase existe

O roadmap v2 (Fases 1-4, 44 jobs, ~508h) assume uma **funda√ß√£o est√°vel**. Hoje a v1 tem bugs cr√≠ticos que impedem o funcionamento b√°sico. A Fase 0 corrige o que est√° quebrado sem construir nada novo ‚Äî o princ√≠pio √© **"consertar, n√£o construir"**.

Tudo que ser√° **reescrito** na v2 recebe apenas a **corre√ß√£o m√≠nima** aqui. Tudo que **n√£o existe na v2** (porque √© infraestrutura b√°sica que a v2 herda) recebe aten√ß√£o adequada.

---

## Diagn√≥stico T√©cnico dos Problemas

### üî¥ CR√çTICO 1: `self_improve` n√£o gera resposta

**Sintoma:** `result.get("response")` retorna `None` quando intent √© `self_improve`.

**Causa raiz** (s√£o duas):

**Causa A ‚Äî Roteamento do grafo est√° errado:**
```python
# graph.py atual
workflow.add_conditional_edges("plan", lambda s: s.get("intent", "unknown"), {
    "self_improve": "respond",  # ‚Üê VAI DIRETO PARA respond, SEM passar por capabilities
})
```
O intent `self_improve` deveria passar por `check_capabilities` ‚Üí `self_improve` ‚Üí `respond`, mas est√° pulando direto para `respond`.

**Causa B ‚Äî `node_generate_response` n√£o trata `self_improve`:**
```python
# nodes.py atual
def node_generate_response(state: AgentState) -> AgentState:
    intent = state.get("intent")
    execution_result = state.get("execution_result")
    
    if execution_result:
        response = execution_result
    elif intent in ["chat", "question"]:  # ‚Üê self_improve N√ÉO EST√Å AQUI
        response = generate_response_sync(...)
    else:
        response = "Comando executado com sucesso! ‚úÖ"  # ‚Üê cai aqui, mas...
    
    return {**state, "response": response}
```

Mesmo que o roteamento fosse corrigido, o n√≥ `respond` n√£o sabe o que fazer com `self_improve`. Se n√£o h√° `execution_result` e o intent n√£o √© `chat` nem `question`, ele retorna a string gen√©rica "Comando executado com sucesso!" ‚Äî **mas isso deveria funcionar**, j√° que ele retorna com `response` na state. O problema real √© provavelmente que o fluxo nem chega ao `respond` ou que o `response` key est√° sendo sobrescrita em algum ponto.

**Investiga√ß√£o necess√°ria:** Verificar no c√≥digo real se existe algum n√≥ ap√≥s `respond` que est√° limpando o state, ou se o `ainvoke` do LangGraph n√£o est√° retornando a key `response`.

### üî¥ CR√çTICO 2: `timezone is not defined`

**Sintoma:** Erro de runtime quando `check_capabilities` √© invocado.

**Causa raiz:** `registry.py` usava `timezone.utc` sem importar `timezone`:
```python
# ANTES (quebrado)
from datetime import datetime
self.created_at = datetime.now(timezone.utc)  # NameError: timezone not defined

# DEPOIS (corrigido?)
from datetime import datetime, timezone
self.created_at = datetime.now(timezone.utc)  # OK
```

**Status:** Segundo o documento, o import foi adicionado mas **n√£o foi testado**. √â necess√°rio confirmar que o fix est√° no c√≥digo real da VPS e rodar um teste.

### üî¥ CR√çTICO 3: C√≥digo duplicado em 3 locais

**Sintoma:** Confus√£o sobre qual arquivo √© o "real":
```
/opt/vps-agent/core/
‚îú‚îÄ‚îÄ graph.py              ‚Üê VERS√ÉO ANTIGA (raiz)
‚îú‚îÄ‚îÄ nodes.py              ‚Üê VERS√ÉO ANTIGA (raiz)
‚îú‚îÄ‚îÄ state.py              ‚Üê VERS√ÉO ANTIGA (raiz)
‚îú‚îÄ‚îÄ memory.py             ‚Üê VERS√ÉO ANTIGA (raiz)
‚îú‚îÄ‚îÄ semantic_memory.py    ‚Üê VERS√ÉO ANTIGA (raiz)
‚îú‚îÄ‚îÄ vps_agent/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py          ‚Üê process_message_async (ATIVO)
‚îÇ   ‚îú‚îÄ‚îÄ graph.py          ‚Üê VERS√ÉO ANTIGA?
‚îÇ   ‚îú‚îÄ‚îÄ nodes.py          ‚Üê VERS√ÉO ANTIGA?
‚îÇ   ‚îî‚îÄ‚îÄ semantic_memory.py
‚îú‚îÄ‚îÄ vps_langgraph/
‚îÇ   ‚îú‚îÄ‚îÄ graph.py          ‚Üê build_agent_graph (ATIVO)
‚îÇ   ‚îú‚îÄ‚îÄ nodes.py          ‚Üê node_classify_intent, etc (ATIVO)
‚îÇ   ‚îú‚îÄ‚îÄ state.py          ‚Üê AgentState (ATIVO)
‚îÇ   ‚îî‚îÄ‚îÄ memory.py         ‚Üê AgentMemory (ATIVO)
‚îî‚îÄ‚îÄ capabilities/
    ‚îî‚îÄ‚îÄ registry.py       ‚Üê CapabilitiesRegistry (ATIVO)
```

**Causa raiz:** Evolu√ß√£o org√¢nica do projeto sem cleanup. O c√≥digo come√ßou na raiz, depois foi organizado em `vps_agent/`, e depois refatorado para `vps_langgraph/`. Os arquivos antigos nunca foram removidos.

**Risco:** Um import pode estar puxando o m√≥dulo errado. O Python resolve imports pela ordem do `sys.path`, e se ambos os diret√≥rios est√£o no path, o comportamento √© indeterminado.

### üü° M√âDIO 4: CI/CD falhando

**Sintoma:** Module import errors no GitHub Actions, passa localmente.

**Causa prov√°vel:** Os imports no CI resolvem para o diret√≥rio errado (porque existem 3 c√≥pias dos mesmos m√≥dulos). Localmente funciona porque o `sys.path` √© diferente. Resolver o problema #3 (duplica√ß√£o) provavelmente resolve este tamb√©m.

### üü° M√âDIO 5: `__pycache__` causando problemas

**Causa:** Arquivos `.pyc` antigos no cache do Python referenciando m√≥dulos que foram movidos/renomeados. O Python tenta carregar o bytecode cacheado que aponta para paths que n√£o existem mais.

**Fix simples:** `find /opt/vps-agent -type d -name __pycache__ -exec rm -rf {} +`

### üü¢ PEQUENO 6: Logs n√£o chegam no Telegram

**Causa prov√°vel:** O bot loga para arquivo via `journalctl` mas n√£o tem um handler que envia logs para o chat do Telegram. Isso √© uma feature, n√£o um bug ‚Äî precisa implementar um `TelegramLogHandler`.

---

## Mapeamento de Sobreposi√ß√µes com v2

Este √© o ponto cr√≠tico: **o que corrigimos agora vs. o que ser√° substitu√≠do na v2**.

| Problema v1 | Corre√ß√£o Fase 0 | Substitu√≠do na v2 por... | Decis√£o |
|---|---|---|---|
| Graph flow self_improve | Fix m√≠nimo no roteamento | F2-01 Skill Registry (substitui capabilities inteiro) | ‚úÖ Fix m√≠nimo agora |
| timezone error | Confirmar import correto | F2-01 Skill Registry (reescreve registry) | ‚úÖ Fix agora (30min) |
| C√≥digo duplicado | Consolidar em vps_langgraph/, deletar c√≥pias | F1-* (nova estrutura de diret√≥rios) | ‚úÖ Cleanup agora, reestruturar na F1 |
| CI/CD falhando | Fix imports + cleanup | F1-12 Testes + F4-10 Environment Segregation | ‚úÖ Fix agora |
| `__pycache__` | Limpar + adicionar ao .gitignore | ‚Äî (boas pr√°ticas permanentes) | ‚úÖ Fix agora |
| Logs no Telegram | Log handler b√°sico | F1-08 Structured Logging (structlog) | ‚úÖ Handler simples agora |
| Qdrant integra√ß√£o | ‚Äî | F3-04 Hierarchical Memory + F3-05 RAG Pipeline | ‚ùå **N√ÉO FAZER AGORA** |
| LLM routing | ‚Äî | F3-01 Failover + F3-02 Model Cascade | ‚ùå **N√ÉO FAZER AGORA** |
| Multi-agent | ‚Äî | F4-01 + F4-02 | ‚ùå **N√ÉO FAZER AGORA** |
| Self-improvement sandbox | ‚Äî | F2-03 Action Classification + F4-04 Self-Improvement Pipeline | ‚ùå **N√ÉO FAZER AGORA** |
| Embedding model choice | ‚Äî | F3-04 Hierarchical Memory | ‚ùå **N√ÉO FAZER AGORA** |
| Semantic caching | ‚Äî | F3-06 Semantic Caching | ‚ùå **N√ÉO FAZER AGORA** |

**Regra de ouro:** Se a v2 tem um job dedicado para resolver algo de forma robusta, a Fase 0 s√≥ faz o **m√≠nimo** para destravar o funcionamento.

---

## Jobs da Fase 0

### FASE 0 ‚Äî Estabiliza√ß√£o v1 (1-2 semanas)
> Objetivo: Agente funcional end-to-end via Telegram. Nenhuma feature nova ‚Äî apenas bugs resolvidos e c√≥digo limpo.

| # | Job | Horas Est. | Prioridade | Pr√©-requisito |
|---|-----|-----------|------------|---------------|
| F0-01 | **Cleanup de C√≥digo** ‚Äî Eliminar duplica√ß√£o. Consolidar em `vps_langgraph/` como m√≥dulo can√¥nico. Deletar `core/graph.py`, `core/nodes.py`, `core/state.py`, `core/memory.py`, `core/semantic_memory.py`. Atualizar todos os imports em `vps_agent/agent.py` e `telegram-bot/bot.py`. Limpar **todos** os `__pycache__`. Adicionar `__pycache__/` e `*.pyc` ao `.gitignore`. | 4h | P0 | ‚Äî |
| F0-02 | **Fix Graph Flow self_improve** ‚Äî Corrigir roteamento no grafo LangGraph para que `self_improve` passe por `check_capabilities` antes de `respond`. Garantir que `node_generate_response` trate o intent `self_improve` chamando LLM com contexto de capabilities. Testar fluxo completo: mensagem ‚Üí classify ‚Üí capabilities ‚Üí respond ‚Üí resposta no Telegram. | 6h | P0 | F0-01 |
| F0-03 | **Fix timezone + Valida√ß√£o** ‚Äî Confirmar import `timezone` em `capabilities/registry.py`. Rodar teste unit√°rio que cria uma `Capability` e verifica `created_at`. Verificar se existem outros usos de `timezone` sem import no projeto. | 1h | P0 | F0-01 |
| F0-04 | **Fix CI/CD** ‚Äî Corrigir imports no GitHub Actions. Garantir que `PYTHONPATH` inclui apenas `core/vps_langgraph/` (n√£o os diret√≥rios duplicados). Adicionar `.env.example` para vari√°veis de ambiente necess√°rias no CI. Verificar se `requirements.txt` est√° completo. Target: pipeline verde. | 4h | P0 | F0-01 |
| F0-05 | **Testes B√°sicos end-to-end** ‚Äî Escrever 5 testes que cobrem os 5 intents: `command`, `task`, `question`, `chat`, `self_improve`. Cada teste: cria state ‚Üí roda grafo ‚Üí verifica que `response` n√£o √© None. Mock de LLM com respostas fixas. Usar `pytest` + `pytest-asyncio`. | 6h | P1 | F0-02, F0-03 |
| F0-06 | **Telegram Log Handler** ‚Äî Handler de logging Python que envia mensagens de n√≠vel ERROR e CRITICAL para o chat do Telegram do admin. N√£o enviar DEBUG/INFO (spam). Rate limit de 1 msg/min para n√£o ser bloqueado pela API do Telegram. | 3h | P1 | F0-01 |
| F0-07 | **Documenta√ß√£o M√≠nima** ‚Äî Atualizar README com: estrutura real de arquivos (p√≥s-cleanup), como rodar localmente, como rodar testes, como fazer deploy. N√£o documentar features futuras. | 2h | P2 | F0-01 |

**Subtotal Fase 0: 7 jobs | ~26h | 1-2 semanas**

---

## Corre√ß√µes de C√≥digo Concretas

### Corre√ß√£o F0-02: Fix do Graph Flow

O grafo precisa de duas mudan√ßas:

**Mudan√ßa 1 ‚Äî Roteamento correto para `self_improve`:**
```python
# core/vps_langgraph/graph.py ‚Äî CORRIGIDO

def build_agent_graph():
    workflow = StateGraph(AgentState)
    
    # N√≥s (mant√©m todos)
    workflow.add_node("classify", node_classify_intent)
    workflow.add_node("load_context", node_load_context)
    workflow.add_node("plan", node_plan)
    workflow.add_node("execute", node_execute)
    workflow.add_node("respond", node_generate_response)
    workflow.add_node("save_memory", node_save_memory)
    workflow.add_node("check_capabilities", node_check_capabilities)
    workflow.add_node("self_improve", node_self_improve)
    workflow.add_node("implement_capability", node_implement_capability)
    
    # Fluxo principal
    workflow.set_entry_point("classify")
    workflow.add_edge("classify", "load_context")
    workflow.add_edge("load_context", "plan")
    
    # CORRE√á√ÉO: self_improve vai para check_capabilities, N√ÉO para respond
    workflow.add_conditional_edges("plan", lambda s: s.get("intent", "unknown"), {
        "command": "execute",
        "task": "execute",
        "question": "respond",
        "chat": "respond",
        "self_improve": "check_capabilities",  # ‚Üê CORRIGIDO
        "unknown": "respond",
    })
    
    # Fluxo de execu√ß√£o
    workflow.add_edge("execute", "respond")
    
    # Fluxo de self_improve: capabilities ‚Üí self_improve ‚Üí respond
    workflow.add_conditional_edges("check_capabilities", 
        lambda s: "self_improve" if s.get("needs_new_capability") else "respond",
        {
            "self_improve": "self_improve",
            "respond": "respond",
        }
    )
    workflow.add_edge("self_improve", "respond")
    
    # Todos os caminhos terminam em save_memory
    workflow.add_edge("respond", "save_memory")
    workflow.set_finish_point("save_memory")
    
    return workflow.compile()
```

**Mudan√ßa 2 ‚Äî `node_generate_response` trata `self_improve`:**
```python
# core/vps_langgraph/nodes.py ‚Äî CORRIGIDO

def node_generate_response(state: AgentState) -> AgentState:
    """Gera resposta final ao usu√°rio."""
    intent = state.get("intent")
    execution_result = state.get("execution_result")
    
    # Prioridade 1: se j√° tem resultado de execu√ß√£o, usar
    if execution_result:
        response = execution_result
    
    # Prioridade 2: self_improve ‚Äî reportar o que aconteceu
    elif intent == "self_improve":
        capability_result = state.get("capability_result")
        if capability_result:
            response = f"üîß Self-Improvement:\n{capability_result}"
        else:
            # Capabilities checadas mas nada novo necess√°rio
            capabilities_info = state.get("capabilities_info", "")
            prompt = (
                f"O usu√°rio pediu algo que envolve self-improvement. "
                f"Capacidades atuais: {capabilities_info}\n"
                f"Mensagem do usu√°rio: {state.get('user_message')}\n"
                f"Explique o que o sistema pode fazer e o que ser√° implementado."
            )
            response = generate_response_sync(prompt)
    
    # Prioridade 3: chat/question ‚Äî chamar LLM
    elif intent in ["chat", "question"]:
        response = generate_response_sync(
            state.get("user_message"),
            context=state.get("context", ""),
        )
    
    # Fallback
    else:
        response = (
            f"Recebi sua mensagem (intent: {intent}). "
            "N√£o tenho certeza de como processar, mas registrei."
        )
    
    return {**state, "response": response}
```

### Corre√ß√£o F0-01: Estrutura p√≥s-cleanup

Ap√≥s eliminar duplicatas, a estrutura deve ficar:
```
/opt/vps-agent/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ vps_langgraph/          # ‚Üê M√ìDULO CAN√îNICO
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py            # build_agent_graph()
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.py            # todos os node_*
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py            # AgentState
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory.py           # AgentMemory
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ vps_agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.py            # process_message_async (imports de vps_langgraph)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ capabilities/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registry.py         # CapabilitiesRegistry
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openrouter_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent_identity.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ resource-manager/
‚îÇ       ‚îî‚îÄ‚îÄ manager.py
‚îÇ
‚îú‚îÄ‚îÄ telegram-bot/
‚îÇ   ‚îî‚îÄ‚îÄ bot.py
‚îÇ
‚îú‚îÄ‚îÄ configs/
‚îú‚îÄ‚îÄ scripts/
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ .gitignore                   # ‚Üê inclui __pycache__/, *.pyc
```

**Deletar:**
- `core/graph.py` (vers√£o antiga na raiz)
- `core/nodes.py` (vers√£o antiga na raiz)
- `core/state.py` (vers√£o antiga na raiz)
- `core/memory.py` (vers√£o antiga na raiz)
- `core/semantic_memory.py` (vers√£o antiga na raiz)
- `core/vps_agent/graph.py` (vers√£o antiga em vps_agent)
- `core/vps_agent/nodes.py` (vers√£o antiga em vps_agent)
- `core/vps_agent/semantic_memory.py` (mover l√≥gica √∫til para vps_langgraph primeiro se necess√°rio)

---

## Respostas √†s 30 Perguntas

### 10.1 Corre√ß√µes Imediatas

**P1: Por que `result.get("response")` retorna `None` para intent `self_improve`?**

Tr√™s poss√≠veis causas, em ordem de probabilidade:

1. **O n√≥ `respond` nunca √© alcan√ßado.** Se o roteamento condicional ap√≥s `plan` manda `self_improve` para `check_capabilities`, mas `check_capabilities` n√£o tem edge de sa√≠da para `respond`, o grafo pode terminar prematuramente. Verificar no c√≥digo real se **todos os caminhos** ap√≥s `check_capabilities` eventualmente chegam em `respond`.

2. **O LangGraph n√£o retorna a key.** O `ainvoke()` do LangGraph retorna apenas as keys que foram **modificadas** pelo √∫ltimo n√≥, n√£o o state inteiro. Se `save_memory` (o √∫ltimo n√≥) n√£o retorna `response` no seu dict, ela desaparece do resultado. Solu√ß√£o: o √∫ltimo n√≥ deve retornar `{**state}` completo, ou usar `result_keys` expl√≠cito na compila√ß√£o.

3. **`node_generate_response` n√£o seta `response`.** Se o intent √© `self_improve` e n√£o cai em nenhum `if`, a vari√°vel `response` nunca √© atribu√≠da e o `return` falha silenciosamente.

**A corre√ß√£o est√° no c√≥digo da se√ß√£o anterior.** Implementar as duas mudan√ßas (roteamento + tratamento de intent).

**P2: Qual √© a corre√ß√£o m√≠nima para `node_generate_response`?**

A **corre√ß√£o m√≠nima absoluta** (1 linha):
```python
elif intent in ["chat", "question"]:
# ‚Üì MUDAR PARA:
elif intent in ["chat", "question", "self_improve"]:
```

Isso faz o `self_improve` ser tratado como `question` ‚Äî chama o LLM com a mensagem do usu√°rio. N√£o √© ideal (n√£o usa o resultado de capabilities), mas **funciona** e gera uma resposta.

A corre√ß√£o completa est√° na se√ß√£o anterior e √© recomendada.

**P3: O import de `timezone` em `capabilities/registry.py` foi corrigido corretamente?**

O fix te√≥rico est√° correto:
```python
from datetime import datetime, timezone  # ‚Üê timezone adicionado
```

Mas **precisa ser verificado no c√≥digo real na VPS**. Rodar:
```bash
cd /opt/vps-agent
python3 -c "from core.capabilities.registry import Capability; print('OK')"
```

Se printar "OK", est√° corrigido. Se der `NameError`, o fix n√£o foi salvo.

---

### 10.2 Arquitetura de C√≥digo

**P4: Qual estrutura de pastas √© recomendada?**

`vps_langgraph/` como pasta can√¥nica **para a Fase 0**. Na v2 (Fase 1), a estrutura ser√° completamente reorganizada para:

```
agentvps-v2/
‚îú‚îÄ‚îÄ gateway/        # FastAPI + adapters
‚îú‚îÄ‚îÄ brain/          # LangGraph agent (substitui vps_langgraph/)
‚îú‚îÄ‚îÄ skills/         # Registry + handlers (substitui capabilities/)
‚îú‚îÄ‚îÄ memory/         # Hier√°rquica
‚îú‚îÄ‚îÄ agents/         # Multi-agent
‚îú‚îÄ‚îÄ observability/
‚îú‚îÄ‚îÄ security/
‚îî‚îÄ‚îÄ ...
```

N√£o vale a pena reorganizar para a estrutura v2 agora. Consolidar em `vps_langgraph/` √© suficiente.

**P5: Como resolver a duplica√ß√£o de arquivos?**

A√ß√£o descrita no job F0-01: deletar os arquivos antigos, manter apenas `vps_langgraph/`. Script:
```bash
# ANTES de deletar, verificar diffs para n√£o perder c√≥digo √∫til
diff core/graph.py core/vps_langgraph/graph.py
diff core/nodes.py core/vps_langgraph/nodes.py
diff core/vps_agent/graph.py core/vps_langgraph/graph.py

# Se n√£o houver c√≥digo √∫til nos antigos, deletar
rm core/graph.py core/nodes.py core/state.py core/memory.py core/semantic_memory.py
rm core/vps_agent/graph.py core/vps_agent/nodes.py core/vps_agent/semantic_memory.py

# Limpar caches
find /opt/vps-agent -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null
```

**P6: Qual padr√£o de imports usar?**

**Imports absolutos** para a Fase 0 e v2:
```python
# ‚úÖ CORRETO ‚Äî absoluto, expl√≠cito
from vps_langgraph.graph import build_agent_graph
from vps_langgraph.nodes import node_classify_intent
from capabilities.registry import CapabilitiesRegistry

# ‚ùå EVITAR ‚Äî relativo, amb√≠guo quando h√° duplicatas
from .nodes import node_classify_intent
```

Motivo: com duplicatas existentes, imports relativos s√£o indeterminados. Absolutos deixam claro **qual** m√≥dulo est√° sendo importado. Na v2, absolutos continuam sendo o padr√£o (ex: `from brain.agent import ...`).

---

### 10.3 LangGraph Patterns

**P7: Como fazer o grafo retornar todas as chaves do estado?**

O `ainvoke()` do LangGraph retorna o **state final completo** por padr√£o. Se `response` n√£o aparece, √© porque **nenhum n√≥ setou essa key**. A corre√ß√£o √© garantir que `node_generate_response` sempre retorna `response` no dict.

Se mesmo assim n√£o funcionar, for√ßar explicitamente:
```python
# No √∫ltimo n√≥ (save_memory), retornar o state inteiro
def node_save_memory(state: AgentState) -> AgentState:
    # ... salvar mem√≥ria ...
    return state  # retorna TODO o state, incluindo response
```

Alternativa: usar `output_keys` ao compilar o grafo:
```python
graph = workflow.compile()
# O LangGraph 0.2+ retorna o state completo por padr√£o
```

**P8: Quando usar n√≥s s√≠ncronos vs ass√≠ncronos?**

Regra pr√°tica:
- **S√≠ncrono**: classifica√ß√£o de intent (regex, r√°pido), valida√ß√µes, transforma√ß√µes de dados
- **Ass√≠ncrono**: chamadas a LLM (I/O-bound), consultas a banco, opera√ß√µes de rede

Na v1, `node_classify_intent` √© s√≠ncrono e **est√° correto** ‚Äî √© apenas regex/keyword matching. `node_generate_response` deveria ser async porque chama LLM, mas como o LangGraph aceita fun√ß√µes sync dentro de `ainvoke()`, funciona mesmo sync (s√≥ √© menos eficiente).

**Na v2 (Fase 1), todos os n√≥s com I/O ser√£o async.** Na Fase 0, n√£o mudar.

**P9: Como implementar checkpoints no LangGraph?**

‚Üí **N√ÉO FAZER NA FASE 0.** Ser√° implementado na v2 como parte do Session Manager (F1-02).

Para refer√™ncia futura:
```python
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver.from_conn_string("postgresql://...")
graph = workflow.compile(checkpointer=checkpointer)

# Cada invoca√ß√£o com thread_id permite resumir
config = {"configurable": {"thread_id": "user-123-session-456"}}
result = await graph.ainvoke(initial_state, config)
```

---

### 10.4 Self-Improvement Design

**P10: Qual √© o fluxo ideal para implementar uma nova capacidade?**

**Fase 0 (fix m√≠nimo):**
```
classify ‚Üí load_context ‚Üí plan ‚Üí check_capabilities ‚Üí self_improve ‚Üí respond ‚Üí save_memory
```
O `check_capabilities` verifica se o que o usu√°rio pediu j√° existe. Se n√£o, `self_improve` registra a necessidade. `respond` informa ao usu√°rio o que ser√° feito.

**v2 (Fase 4, job F4-04 ‚Äî Self-Improvement Pipeline):**
```
identify failure pattern ‚Üí propose code change ‚Üí test in sandbox ‚Üí human approval ‚Üí deploy
```
A diferen√ßa √© que na v2 o agente **realmente implementa** c√≥digo novo com guardrails. Na Fase 0, ele apenas **identifica e informa**.

**P11: O agente deve executar c√≥digo gerado automaticamente?**

‚Üí **N√ÉO NA FASE 0.** Executar c√≥digo auto-gerado sem sandbox √© o risco de seguran√ßa #1 do projeto.

Na v2:
- F2-03 implementa **Action Classification** (safe/moderate/dangerous)
- F2-09 implementa **Tool Usage Policies**
- F4-04 implementa o **Self-Improvement Pipeline** com sandbox Docker + human approval

**Sequ√™ncia segura (v2):** gerar c√≥digo ‚Üí rodar em container ef√™mero com filesystem read-only ‚Üí verificar sa√≠da ‚Üí submeter para aprova√ß√£o humana via Telegram ‚Üí aplicar se aprovado.

**P12: Como implementar auto-commit no git?**

‚Üí **N√ÉO NA FASE 0.** Ser√° parte do F4-04 na v2.

Design planejado:
```bash
# O agente cria branch, commita, e pede aprova√ß√£o
git checkout -b self-improve/add-capability-xyz
git add .
git commit -m "feat: add capability xyz [auto-generated]"
# Enviar para Telegram: "Nova capability proposta. Aprovar merge? [Sim/N√£o]"
# Se aprovado: git checkout main && git merge self-improve/add-capability-xyz
# Se rejeitado: git branch -D self-improve/add-capability-xyz
```

**P13: O que fazer em caso de erro na implementa√ß√£o?**

‚Üí **Na Fase 0:** Apenas logar o erro e informar o usu√°rio via Telegram.
‚Üí **Na v2 (F4-04):** Rollback autom√°tico com `git revert`, notifica√ß√£o ao usu√°rio, e log de falha para an√°lise posterior.

---

### 10.5 Mem√≥ria e Contexto

**P14: Quando usar PostgreSQL vs Qdrant?**

‚Üí **Na Fase 0:** Apenas PostgreSQL. Qdrant N√ÉO ser√° integrado agora.

‚Üí **Na v2 (F3-04 Hierarchical Memory):**

| Camada | Storage | O que guarda | Quando consultar |
|---|---|---|---|
| Epis√≥dica | JSONL (arquivos) | Transcripts recentes (<7 dias) | Sempre (contexto imediato) |
| Sem√¢ntica | Qdrant | Fatos importantes, embeddings | Quando precisa de contexto longo-prazo |
| Perfil | PostgreSQL + USER.md | Prefer√™ncias, configs, fatos estruturados | Sempre (perfil do usu√°rio) |

**P15: Como fazer hybrid search (PostgreSQL + Qdrant)?**

‚Üí **Ser√° implementado na v2, Fase 3 (F3-04 + F3-05).**

Design planejado:
```python
# 1. Buscar fatos estruturados no PostgreSQL
structured_facts = await pg.query("SELECT * FROM facts WHERE user_id = $1", user_id)

# 2. Buscar contexto sem√¢ntico no Qdrant
query_embedding = embed(user_message)
semantic_results = await qdrant.search(collection="memories", query_vector=query_embedding, limit=5)

# 3. Combinar com ranking
combined = rank_by_relevance(structured_facts, semantic_results, user_message)
```

**P16: Qual modelo de embedding usar?**

‚Üí **Decis√£o adiada para F3-04.**

Recomenda√ß√£o preliminar baseada na constraint de 2.4GB RAM:

| Modelo | Dimens√£o | RAM | Qualidade | Recomenda√ß√£o |
|---|---|---|---|---|
| `all-MiniLM-L6-v2` | 384 | ~80MB | Boa | ‚úÖ **Usar este** (RAM limitada) |
| `all-mpnet-base-v2` | 768 | ~420MB | Melhor | ‚ùå Muito pesado para 2.4GB |
| Voyage AI / OpenAI embeddings (API) | 1024+ | 0MB local | Excelente | ‚úÖ Alternativa: sem RAM local, custo por chamada |

A alternativa de usar **embeddings via API** (Voyage AI, OpenAI) em vez de rodar modelo local √© a que mais faz sentido para 2.4GB RAM. Custo baixo (~$0.0001 por embedding) e zero RAM local.

---

### 10.6 LLM Routing

**P17: Como router inteligente entre MiniMax M2.1 e Sonnet 4.5?**

‚Üí **Ser√° implementado na v2, Fase 3 (F3-02 Model Cascade Routing).**

Design planejado:
```python
def classify_complexity(message: str, intent: str) -> str:
    """Classifica complexidade para routing de modelo."""
    # Simples: sauda√ß√µes, perguntas factuais curtas, chat casual
    if intent in ["chat", "question"] and len(message) < 100:
        return "simple"  # ‚Üí MiniMax M2.1 / Haiku
    
    # Complexo: c√≥digo, arquitetura, self-improvement, tarefas longas
    if intent in ["self_improve", "task"] or "```" in message:
        return "complex"  # ‚Üí Sonnet 4.5 / Opus
    
    return "medium"  # ‚Üí Sonnet 4.5
```

**P18: Como implementar fallback autom√°tico?**

‚Üí **v2, Fase 3 (F3-01 Multi-Provider LLM Failover).**

**P19: Como fazer cache de respostas?**

‚Üí **v2, Fase 3 (F3-06 Semantic Caching).**

---

### 10.7 Resource Management

**P20: Quando subir o Qdrant?**

‚Üí **Sob demanda.** Com 2.4GB total, Qdrant (~400MB) n√£o pode ficar sempre ligado.

Na v2 (F3-04), o Resource Manager decidir√° quando subir/descer o Qdrant baseado na necessidade. Se uma query precisa de busca sem√¢ntica ‚Üí subir Qdrant ‚Üí consultar ‚Üí manter por 5 minutos ‚Üí desligar se inativo.

**P21: Como gerenciar RAM com 2.4 GB total?**

Budget de RAM:
```
SEMPRE LIGADOS (~750 MB):
  PostgreSQL 16    = ~200 MB
  Redis 7          = ~50 MB
  Python (agent)   = ~300 MB (vps_langgraph + bot + fastapi-mcp)
  Sistema (OS)     = ~200 MB

SOB DEMANDA (~1650 MB restantes):
  Qdrant           = ~400 MB (subir/descer conforme necessidade)
  n8n              = ~300 MB
  Sentence-transf. = ~80-420 MB (depende do modelo; ou usar API)
  Margem seguran√ßa = ~150 MB m√≠nimo

REGRA: nunca rodar mais de 2 servi√ßos sob-demanda simultaneamente
```

Isso ser√° formalizado na v2 como parte do Resource Manager evolu√≠do. Na Fase 0, a estrutura atual j√° funciona ‚Äî s√≥ n√£o rodar Qdrant + n8n ao mesmo tempo.

---

### 10.8 Testing e CI/CD

**P22: Como testar o LangGraph localmente?**

```python
# tests/test_graph.py
import pytest
from unittest.mock import patch, AsyncMock
from vps_langgraph.graph import build_agent_graph

@pytest.mark.asyncio
async def test_chat_intent_returns_response():
    """Testa que intent 'chat' produz response."""
    # Mock do LLM para n√£o depender de API
    with patch("vps_langgraph.nodes.generate_response_sync", return_value="Ol√°!"):
        graph = build_agent_graph()
        result = await graph.ainvoke({
            "user_id": "test-user",
            "user_message": "Ol√°, tudo bem?",
            "timestamp": "2026-02-08T00:00:00Z",
        })
        assert result.get("response") is not None
        assert result["intent"] == "chat"

@pytest.mark.asyncio
async def test_self_improve_intent_returns_response():
    """Testa que intent 'self_improve' produz response."""
    with patch("vps_langgraph.nodes.generate_response_sync", return_value="Vou implementar"):
        graph = build_agent_graph()
        result = await graph.ainvoke({
            "user_id": "test-user",
            "user_message": "Crie um novo agente de monitoramento",
            "timestamp": "2026-02-08T00:00:00Z",
        })
        assert result.get("response") is not None
        assert result["intent"] == "self_improve"
```

**P23: Por que o CI/CD falha no GitHub Actions?**

Causas prov√°veis (em ordem):
1. **Duplica√ß√£o de m√≥dulos** ‚Üí Python importa o m√≥dulo errado. Resolver com F0-01.
2. **`PYTHONPATH` n√£o configurado** ‚Üí CI n√£o sabe onde encontrar os m√≥dulos. Adicionar ao workflow:
   ```yaml
   env:
     PYTHONPATH: /opt/vps-agent/core
   ```
3. **Vari√°veis de ambiente ausentes** ‚Üí `.env` n√£o existe no CI. Criar `.env.example` e carregar no workflow.
4. **Depend√™ncias incompletas** ‚Üí `requirements.txt` faltando pacotes. Rodar `pip freeze` na VPS e comparar.

**P24: Como garantir coverage de testes?**

‚Üí **Fase 0:** Target 40% (apenas os 5 testes de intents, F0-05).
‚Üí **v2 F1-12:** Target 60%.
‚Üí **v2 F2-10:** Target 70%.

Priorizar cobertura em: `graph.py`, `nodes.py`, `agent.py` ‚Äî o core do fluxo.

---

### 10.9 Seguran√ßa

**P25: Como sandbox de self-improvement?**

‚Üí **N√ÉO na Fase 0.** Ser√° v2 Fase 2 (F2-03 Action Classification) + Fase 4 (F4-04).

Design v2:
```bash
# Container ef√™mero para testar c√≥digo gerado
docker run --rm \
  --read-only \
  --tmpfs /tmp:rw,size=100m \
  --network=none \
  --memory=256m \
  --cpus=0.5 \
  --timeout=60 \
  python:3.12-slim \
  python /tmp/generated_code.py
```

**P26: Como proteger credenciais?**

Isso vale **agora** (Fase 0) e continua na v2:
```bash
# .env com permiss√µes restritas
chmod 600 /opt/vps-agent/.env

# No systemd (j√° funciona)
EnvironmentFile=/opt/vps-agent/.env

# NO .gitignore (verificar!)
echo ".env" >> .gitignore

# NUNCA commitar .env ‚Äî usar .env.example sem valores reais
```

---

### 10.9 Future Features

**P27-30:** Multi-agent, web interface, WhatsApp, auto-scaling ‚Äî **todas cobertas pela v2:**

| Pergunta | Resposta v2 |
|---|---|
| P27: Multi-agente | F4-01 + F4-02 (Multi-Agent Routing + Communication) |
| P28: Web interface | ‚ùå Descartado (Telegram + CLI suficientes) |
| P29: WhatsApp | F2-07 (Evolution API Adapter) |
| P30: Auto-scaling | ‚ùå Descartado (single-VPS, n√£o √© SaaS) |

---

## Roadmap Completo Atualizado

| Fase | Jobs | Horas | Semanas | Entrega Principal |
|------|------|-------|---------|-------------------|
| **F0** ‚Äî Estabiliza√ß√£o v1 | 7 | ~26h | 1-2 | Agente funcional end-to-end |
| **F1** ‚Äî Refatora√ß√£o da Funda√ß√£o | 12 | ~102h | 3-4 | Gateway + Sess√µes + Prote√ß√µes |
| **F2** ‚Äî Skills & Seguran√ßa | 10 | ~120h | 3-4 | Skills modulares + WhatsApp + Security |
| **F3** ‚Äî Intelig√™ncia | 11 | ~146h | 4-5 | Failover + RAG + Cache + Automa√ß√µes |
| **F4** ‚Äî Autonomia | 11 | ~140h | 3-4 | Multi-agent + Self-improvement + Guardrails |
| **TOTAL** | **51 jobs** | **~534h** | **14-19 semanas** | |

A Fase 0 adiciona apenas ~26h e 1-2 semanas, mas √© **pr√©-requisito** para todas as outras. Sem ela, n√£o temos uma base funcional para construir a v2.

---

## Crit√©rios de Sa√≠da da Fase 0

A Fase 0 est√° **completa** quando:

- [ ] Mensagem enviada no Telegram com intent `self_improve` retorna resposta (n√£o `None`)
- [ ] Mensagem com intent `chat` retorna resposta
- [ ] Mensagem com intent `command` retorna resposta
- [ ] Mensagem com intent `question` retorna resposta
- [ ] Mensagem com intent `task` retorna resposta
- [ ] Nenhum `NameError: timezone` nos logs
- [ ] Apenas **1 c√≥pia** de cada arquivo (graph.py, nodes.py, state.py, memory.py)
- [ ] `pytest` passa com 5+ testes no CI (GitHub Actions verde)
- [ ] `__pycache__` no `.gitignore`
- [ ] Erros CRITICAL/ERROR aparecem no Telegram

**S√≥ avan√ßar para F1 quando todos os checkboxes estiverem marcados.**

---

## Pr√≥ximos Passos Imediatos

1. **Acessar a VPS** e verificar o estado real do c√≥digo (os snippets do doc podem estar desatualizados)
2. **Executar F0-01** ‚Äî cleanup √© pr√©-requisito de tudo
3. **Executar F0-02 + F0-03** ‚Äî corrigir os bugs cr√≠ticos
4. **Rodar teste manual via Telegram** ‚Äî enviar mensagens com cada intent e verificar respostas
5. **Executar F0-04** ‚Äî CI verde
6. **F0-05 a F0-07** em paralelo

Tempo estimado para ter o agente funcional: **1 semana focada** ou **2 semanas em ritmo normal**.
